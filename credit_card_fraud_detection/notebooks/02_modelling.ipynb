{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5e77a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ Add the project root (one level above /notebooks) to the very beginning of sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# 2️⃣ Import after the path has been updated\n",
    "from ccfd_utils.preprocessing import preprocess_data\n",
    "\n",
    "# 3️⃣ Load and preprocess the data\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221ada6",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION\n",
    "\n",
    "To establish a baseline, a Logistic Regression classifier was trained on the preprocessed dataset using class weighting to address the imbalance between fraudulent and non-fraudulent transactions. The model achieved a high overall accuracy of ~98%, however this number is misleading due to the severe class imbalance. More importantly, it achieved a recall of 0.92 for the fraud class, meaning it was able to correctly detect most fraudulent transactions.\n",
    "On the other hand, the precision for the fraud class was only 0.06, indicating a large number of false positives.\n",
    "This makes Logistic Regression a good baseline for sensitivity (recall), but further models are necessary to improve precision without significantly reducing recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ee038e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56864\n",
      "           1       0.06      0.92      0.11        98\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.95      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n",
      "[[55478  1386]\n",
      " [    8    90]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, lr_pred))\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33516a",
   "metadata": {},
   "source": [
    "DECISION TREES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d804d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.72      0.71      0.72        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.86      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56837    27]\n",
      " [   28    70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Decision Tree Model\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced')\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "print(\"Decision Tree:\\n\", classification_report(y_test, dt_pred))\n",
    "print(confusion_matrix(y_test, dt_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
